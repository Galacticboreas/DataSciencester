# Доверительные интервалы

# Мы проверяли гиротезы о значении вероятности орлов р, т.е. параметре
# неизвестного распределения "орлов". В этом случае используют третий
# подход - строят доверительный интервал вокруг наблюдаемого значения
# параметра.

# Например, мы можем оценить вероятность неуравновешенной монеты, обра-
# тившись к среднему значению бернуллиевых величин, соответствующих
# каждому броску монеты - 1(орел) и 0 (решка). Если мы наблюдаем 525
# орлов из 1000 бросков, то мы оцениваем, что р равно 0.525.

# Насколько можно быть уверенным в этой оценке? Дело в том, что если
# бы имелось точное значение р, то согласно центральной предельной 
# теореме среднее этих бернуллиевых величин должно быть приближенно 
# нормальным со средним р и стандартным отклонением:

import math, random
from typing import Tuple, List



def normal_cdf(x: float, mu: float = 0, sigma: float = 1) -> float:
    return (1 + math.erf((x - mu) / math.sqrt(2) / sigma)) / 2

def inverse_normal_cdf(p: float,
                       mu: float = 0,
                       sigma: float = 1,
                       tolerance: float = 0.00001) -> float:
    """Находит приблизительное обратное с помощью двоичного поиска"""

    # if not standard, compute standard and rescale
    if mu != 0 or sigma != 1:
        return mu + sigma * inverse_normal_cdf(p, tolerance=tolerance)

    low_z = -10.0                      # normal_cdf(-10) is (very close to) 0
    hi_z  =  10.0                      # normal_cdf(10)  is (very close to) 1
    while hi_z - low_z > tolerance:
        mid_z = (low_z + hi_z) / 2     # Consider the midpoint
        mid_p = normal_cdf(mid_z)      # and the cdf's value there
        if mid_p < p:
            low_z = mid_z              # Midpoint too low, search above it
        else:
            hi_z = mid_z               # Midpoint too high, search below it

    return mid_z

# Верхняя граница
def normal_upper_bound(probability: float,
                       mu: float = 0,
                       sigma: float = 1) -> float:
    """Возвращает z, для которой P(Z <= z) = вероятность"""
    return inverse_normal_cdf(probability, mu, sigma)

# Нижняя граница
def normal_lower_bound(probability: float,
                       mu: float = 0,
                       sigma: float = 1) -> float:
    """Возвращает z, для которой P(Z >= z) = вероятность"""
    return inverse_normal_cdf(1 - probability, mu, sigma)

# Двусторонняя граница
def normal_two_sided_bounds(probability: float,
                            mu: float = 0,
                            sigma: float = 1) -> Tuple[float, float]:
    """Возвращает симметрические (вокруг среднего) границы,
       которые содержат указанную вероятность
    """
    tail_probability = (1 - probability) / 2

    # Верхняя граница должна иметь хвостовую tail_probability выше ее
    upper_bound = normal_lower_bound(tail_probability, mu, sigma)

    # Нижняя граница должна иметь хвостовую tail_probability ниже ее
    lower_bound = normal_upper_bound(tail_probability, mu, sigma)
    return lower_bound, upper_bound

# math.sqrt(p * (1 - p) / 100)

# Здесь мы не знаем р, и поэтому вместо него мы используем оценку:

p_hat = 525 / 1000
mu = p_hat
sigma = math.sqrt(p_hat * (1 - p_hat) / 1000)   # 0.0158

# Это не совсем оправданно, и тем не менее все равно поступают именно
# так. Используя нормальную аппроксимацию, мы делаем вывод, что с
# "уверенностью на 95%" следующий ниже интервал содержит истинный 
# параметр р:

normal_two_sided_bounds(0.95, mu, sigma)     # [0.4940, 0.5560]

# Это утверждение касается интервала, а не р. Следует понимать его
# как утверждение, что если бы пришлось повторять эксперимент много
# раз, то в 95% случаев "истинный" параметр (который каждый раз одинаков)
# будет лежать в пределах наблюдаемого доверительного интервала (который
# каждый раз может быть разным).

# В частности, мы не делаем заключения о том, что монета не уравновешена,
# поскольку 0.5 попадает в пределы доверительного интервала.

# И напротив, если бы выпало 540 орлов, то мы имели бы:

p_hat = 540 / 1000
mu = p_hat
sigma = math.sqrt(p_hat * (1 - p_hat) / 1000)   # 0.0158

normal_two_sided_bounds(0.95, mu, sigma)    # [0.5091, 0.5709]

# Здесь "уравновешенная монета" не лежит в доверительном интервале.
# (Гипотеза об уравновешенной монете не проходит проверки, которую,
# как ожидалось, она должна проходить в 95% случаев, если бы она
# была истинной.)

# Взлом р-значения

# Процедура, которая отклоняет нелувую гиротезу только в 5% случаев -
# по определению, - в 5% случаев будет отклонять нулевую гиротезу 
# ошибочно:

def run_experiment() -> List[bool]:
    """Подбрасывает уравновешенную монету 1000 раз,
       Истина = орлы, Ложь = решки"""
    return [random.random() < 0.5 for _ in range(1000)]

def reject_fairness(experiment: List[bool]) -> bool:
    """Использование 5%-ных уровней значимости"""
    num_heads = len([flip for flip in experiment if flip])
    return num_heads < 469 or num_heads > 531

random.seed(0)
experiments = [run_experiment() for _ in range(1000)]

num_rajections = len([experiment
                      for experiment in experiments
                      if reject_fairness(experiment)])

assert num_rajections == 46

# А это означает, что если задаться целью найти "значимые" результаты, то их
# обязательно найдешь. Проверь достаточное число гипотез относительно данных,
# и одна из них почти наверняка покажется значимой. Удали правильные выбросы, и 
# в итоге вы вполне можете получить р-значение ниже 0.05. (Нечто отдаленно
# похожее было сделано в разд. "Корреляция" главы 5. Заметили?)

# Это то, что называется взлом р-значения (p-hacking) и в некоторой степени
# является следствием "вывода в рамках р-значений". По этой теме имеется
# замечательная статья "Земля круглая", в которой критикуется такой подход.

# Если вы хотите заниматься "хорошей" наукой о данных, то вам следует формули-
# ровать свои гипотезы до обращения к данным, вы должны очищать данные, не
# держа в уме гипотезы, и понимать, что р-значения - это не заменители здра-
# вого смысла. (Альтернативный подход рассмотрен в разд. "Байесов вывод"
# далее в этой главе.)

# ----------------------------------------------------------------------------
# Пример: проведение А/В-тестирования
# ----------------------------------------------------------------------------

# Одна из ваших первостепенных обязанностей в DataSciencester - заниматься
# оптимизацией опыта взаимодействия. Под этим эвфемизмом скрываются усилия
# заставить пользователей щелкать на рекламных объявлениях. Один из реклам-
# ных агентов разработал рекламу нового энергетического напитка, предназна-
# ченного для иследователей данных, и директору отдела по рекламе нужна
# ваша помощь с выбором между двумя рекламными обьявлениями: А("Вкус отличный!")
# и В("Меньше предвзятости!").

# Будучи исследователем, вы решаете провести эксперимент, случайно показывая
# посетителями веб-сайта одно из двух рекламных сообщений, при этом отслежи-
# вая число нажатий на каждом из них.

# Если из 1000 потребителей рекламы А ее выбрали 990 человек, а из 1000 потре-
# бителей рекламы В ее выбрали только 10 человек, то можно быть вполне уверен-
# ным, что реклама А лучше. Но что делать, если разница не такая большая? Как
# раз здесь и понадобиться статистический вывод.

# Скажем, Na людей видят рекламу А и na из них нижимают на ней. Каждый про-
# смотр рекламы можно представить в виде бернуллиева испытания, где ра - это
# вероятность, что кто-то нажмет на рекламе А. Тогда (если Na большое, что
# так и есть в данном случае) мы знаем, что na/Na - это приближенно нормальная
# случайная величина со средним значением ра и стандартным отклонением.

def estimated_parameters(N: int, n: int) -> Tuple[float, float]:
    p = n / N
    sigma = math.sqrt(p * (1 - p) / N)
    return p, sigma

# Поэтому можно проверить нулевую гиротезу о том, что ра и рв являются
# одинаковыми (т.е. ра - рв = 0), используя следующую статистику:

def a_b_test_statistic(N_A: int, n_A: int, N_B: int, n_B: int) -> float:
    p_A, sigma_A = estimated_parameters(N_A, n_A)
    p_B, sigma_B = estimated_parameters(N_B, n_B)
    return (p_B - p_A) / math.sqrt(sigma_A ** 2 + sigma_B ** 2)
# которая должна быть приближенно стандартной нормальной.

# Например, если реклама "Вкус отличный!" получает 200 кликов из 1000
# просмотров, а реклама "Меньше предвзятости!" - 180 кликов из такого
# же числа, то статистика равна:

z = a_b_test_statistic(1000, 200, 1000, 180)   # -1.14

# Вероятность наблюдать такую большую разницу, если средние значения были
# бы фактически одинаковыми, будет:

def normal_cdf(x: float, mu: float = 0, sigma: float = 1) -> float:
    return (1 + math.erf((x - mu) / math.sqrt(2) / sigma)) / 2

normal_probability_below = normal_cdf

def normal_probability_above(lo: float,
                             mu: float = 0,
                             sigma: float = 1) -> float:
    """Вероятность, что N(mu, sigma) выше, чем lo."""
    return 1 - normal_cdf(lo, mu, sigma)

# Двустороннее р-значение
def two_sided_p_value(x: float, mu: float = 0, sigma: float = 1) -> float:
    """
    Насколько правдоподобно увидеть значение, как минимум, такое же
    предельное, что и х (в любом направлении), если наши значения
    поступают из N(mu, sigma)?
    """
    if x >= mu:
        # x больше, чем среднее, поэтому хвост везде больше, чем х
        return 2 * normal_probability_above(x, mu, sigma)
    else:
        # x меньше, чем среднее, поэтому хвост везде меньше, чем х
        return 2 * normal_probability_below(x, mu, sigma)

two_sided_p_value(z)                           # 0.254

# которая большая настолько, что мы можем сделать вывод о наличии
# большой разницы. С другой стороны, если реклама "Меньше предвзятости!"
# получит только 150 откликов, то мы получим:

z = a_b_test_statistic(1000, 200, 1000, 150)   # -2.94

two_sided_p_value(z)                           # 0.003
