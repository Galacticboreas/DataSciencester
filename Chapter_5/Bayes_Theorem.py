# ----------------
#   Вероятность   |
# ----------------

#  Теорема Байеса

# Лучшим другом исследователя данных является теорема Байеса, которая
# позволяет "переставлять" условные вероятности местами. Скажем, нам
# нужно узнать вероятность некоего события Е, зависящего от наступления
# некоего другого события F, причем в наличии имеется лишь информация
# о вероятности события F, зависящего от наступления события Е. Двукратное
# применение (в силу симметрии) определения условной вероятности даст
# формулу Байеса: см.книгу стр. №105.

# Случайные величины

# Случайная величина - это переменная, возможные значения которой ассо-
# циированы с распределением вероятностей. Простая случайная величина
# равна 1, если подброшенная монета повернется орлом, и 0, если повернется
# решком. Более сложная величина может измерять число орлов, наблюдаемых
# при 10 бросках, или значение, выбираемое из интервала range(10), где
# каждое число является равновероятным. См. книгу, стр. №106

# Непрерывные распределения

# Бросание монеты соответствует дискретному распределению, т.е. такому,
# которое ассоцирует положительную вероятность с дискретными исходами.

# Функция плотности равномерного распределения - это всего лишь:
def uniform_pdf(x: float) -> float:
    return 1 if x >= 0 and x < 1 else 0

# Реализация указанной функции для равномерного распределения является
# элементарной:
def uniform_cdf(x: float) -> float:
    """Возвращает вероятность, что равномерно
       распределенная случайная величина <= x"""
    if x < 0:   return 0 # Равномерная величина никогда не бывает меньше 0
    elif x < 1: return x   # Например, P(X <= 0.4) = 0.4
    else:       return 1   # Равномерная величина всегда меньше 1

# Нормальное распределение

# Нормальное распределение - это классическое колоколообразное распределение.
# Оно полностью определяется двумя параметрами: его средним значением (мю)
# и его стандартным отклонением (сигмой). Среднее значение указывает, где
# колокол центрирован, а стандартное отклонение - наскролько "широким" он
# является.

# Функцию плотности расределения можно имплементировать слудующим образом:
import math
SQRT_TWO_PI = math.sqrt(2 * math.pi)

def normal_pdf(x: float, mu: float = 0, sigma: float = 1) -> float:
    return (math.exp(-(x-mu) ** 2 / 2 / sigma ** 2) / (SQRT_TWO_PI * sigma))

import matplotlib.pyplot as plt

xs = [x / 10.0 for x in range(-50, 50)]
plt.plot(xs, [normal_pdf(x, sigma=1) for x in xs], '-', label='мю=0, сигма=1')
plt.plot(xs, [normal_pdf(x, sigma=2) for x in xs], '--', label='мю=0, сигма=2')
plt.plot(xs, [normal_pdf(x, sigma=0.5) for x in xs], ':', label='мю=0, сигма=0.5')
plt.plot(xs, [normal_pdf(x, mu=-1) for x in xs], '-.', label='мю=-1, сигма=1')
plt.legend()
plt.title("Различные нормальные функции плотности вероятности")
plt.show()

# Кумулятивную функцию (CDF) для нормального распределения невозможно написать,
# пользуясь лишь "элементарными" средствами, однако это можно сделать при
# помощи функции интеграла вероятности math.erf языка Python:

def normal_cdf(x: float, mu: float = 0, sigma: float = 1) -> float:
    return (1 + math.erf((x - mu) / math.sqrt(2) / sigma)) / 2

# И снова построим графики некоторых из кумулятивных функций:

xs = [x / 10.0 for x in range(-50, 50)]
plt.plot(xs, [normal_cdf(x, sigma=1) for x in xs], '-', label='мю=0, сигма=1')
plt.plot(xs, [normal_cdf(x, sigma=2) for x in xs], '--', label='мю=0, сигма=2')
plt.plot(xs, [normal_cdf(x, sigma=0.5) for x in xs], ':', label='мю=0, сигма=0.5')
plt.plot(xs, [normal_cdf(x, mu=-1) for x in xs], '-.', label='мю=-1, сигма=1')
plt.legend(loc=4)   # внизу справа
plt.title("Различные нормальные кумулятивные функции распределения")
plt.show()

# Иногда нам нужно инвертировать кумулятивную функцию normal_cdf, чтобы
# отыскать значение, соответствующее указанной вероятности. Простой
# способ вычислить обратную функцию отсутствует, однако если учесть, что
# normal_cdf - непрерывная и монотонно возрастающая функция, то можно
# применить двоичный поиск:

def inverse_normal_cdf(p: float,
                       mu: float = 0,
                       sigma: float = 1,
                       tolerance: float = 0.00001) -> float:   # задать точность
    """Отыскать приближенную инверсию, используя бинарный поиск"""
    # Если не стандартная, то вычислить стандартную и перешкалировать
    if mu != 0 or sigma !=1:
        return mu + sigma * inverse_normal_cdf(p, tolerance=tolerance)

    low_z = -10.0    # normal_cdf(-10) равно (находится очень близко к) 0
    hi_z = 10.0      # normal_cdf(10) равно (находится очень близко к) 1

    while hi_z - low_z > tolerance:
        mid_z = (low_z + hi_z) / 2   # Рассиотреть среднюю точку
        mid_p = normal_cdf(mid_z)    # и значение CDF
        if mid_p < p:
            low_z = mid_z   # Средняя точка слишком низкая, искать выше
        else:
            hi_z = mid_z    # Средняя точка слишком высокая, искать ниже
    return mid_z

# Функция многократно делит нитервалы пополам, пока не выйдет на точку Z,
# которая достаточно близка к требуемой вероятности.
